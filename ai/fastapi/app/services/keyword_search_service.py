"""
í‚¤ì›Œë“œ ê²€ìƒ‰ ì„œë¹„ìŠ¤ (LaBSE ëª¨ë¸)
"""
import pickle
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import logging
import os

logger = logging.getLogger(__name__)

class KeywordSearchService:
    def __init__(self):
        self.model = None
        self.keywords = None
        self.ids = None
        self.embeddings = None
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        self.pkl_file_path = os.getenv('DATA_PATH', '/app/data') + '/keyword_embeddings_labse.pkl'
        self.model_cache_dir = os.getenv('TRANSFORMERS_CACHE', '/app/models')
        
        self._ready = False
        
    def initialize(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸš€ LaBSE ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.model = SentenceTransformer('LaBSE', cache_folder=self.model_cache_dir)
            
            logger.info(f"ğŸ“ PKL íŒŒì¼ ë¡œë”©: {self.pkl_file_path}")
            if not os.path.exists(self.pkl_file_path):
                logger.error(f"âŒ PKL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.pkl_file_path}")
                return False
                
            with open(self.pkl_file_path, 'rb') as f:
                data = pickle.load(f)
            
            self.keywords = data['keywords']
            self.ids = data['ids']
            self.embeddings = data['embeddings']
            
            logger.info(f"âœ… í‚¤ì›Œë“œ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: {len(self.keywords)}ê°œ í‚¤ì›Œë“œ")
            self._ready = True
            return True
            
        except FileNotFoundError:
            logger.error(f"âŒ PKL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.pkl_file_path}")
            return False
        except Exception as e:
            logger.error(f"âŒ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            return False
    
    def is_ready(self):
        """ì„œë¹„ìŠ¤ ì¤€ë¹„ ìƒíƒœ í™•ì¸"""
        return self._ready and self.model is not None and self.keywords is not None
    
    def search(self, korean_query, top_k=5):
        """í•œêµ­ì–´ ê²€ìƒ‰ì–´ë¡œ ìœ ì‚¬í•œ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        if not self.is_ready():
            raise ValueError("ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # í•œêµ­ì–´ ê²€ìƒ‰ì–´ ë²¡í„°í™”
            query_embedding = self.model.encode([korean_query])
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = cosine_similarity(query_embedding, self.embeddings)[0]
            
            # ìƒìœ„ kê°œ ì¸ë±ìŠ¤
            top_indices = similarities.argsort()[-top_k:][::-1]
            
            # ê²°ê³¼ ë°˜í™˜
            results = []
            for idx in top_indices:
                results.append({
                    'keyword': self.keywords[idx],
                    'id': self.ids[idx],
                    'score': float(similarities[idx]),
                    'rank': len(results) + 1
                })
            
            logger.info(f"ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ ì™„ë£Œ: '{korean_query}' -> {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            raise
    
    def get_stats(self):
        """ì„œë¹„ìŠ¤ í†µê³„ ì •ë³´"""
        return {
            'service': 'keyword-search',
            'model_name': 'LaBSE',
            'ready': self.is_ready(),
            'keyword_count': len(self.keywords) if self.keywords else 0,
            'embedding_dimension': self.embeddings.shape[1] if self.embeddings is not None else 0
        }